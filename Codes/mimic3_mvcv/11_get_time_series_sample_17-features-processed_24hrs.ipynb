{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get time series for 17 processed features\n",
    "\n",
    "This script is used for generating time series for 17 processed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sys.path.append(\"..\")\n",
    "# from dataprocessing.util import make_splits\n",
    "\n",
    "def try_making_splits(y, nfold, test_ratio=None):\n",
    "    '''\n",
    "    y: n*n_class\n",
    "        tries to find n splits, where:\n",
    "        size of (train, valid, test) is (nfold-2, 1, 1)\n",
    "        # of samples for one class is (>=1/2, >=0.5*ratio, >=0.5*ratio)\n",
    "    '''\n",
    "    idx_list = np.empty([nfold, 3], dtype=object)\n",
    "    if test_ratio is None:\n",
    "        test_ratio = 1.0 / nfold\n",
    "    n_samples, n_classes = y.shape\n",
    "    i_class_least = np.argmin(np.sum(y, axis=0))\n",
    "    i_trial = 0\n",
    "    print('\\nnew try: ', i_trial,)\n",
    "    cnt = 0\n",
    "    while i_trial < nfold:\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print('{} trials'.format(cnt))\n",
    "        success_flag = True\n",
    "        ss = StratifiedShuffleSplit(y[:, i_class_least], n_iter=1,\n",
    "                                    test_size=test_ratio)\n",
    "        for idx_trva, idx_te in ss:  # length is only 1 !\n",
    "            for i_class in range(n_classes):\n",
    "                te_percent = 1.0 * np.sum(y[idx_te, i_class]) / np.sum(y[:, i_class])\n",
    "                trva_percent = 1.0 * np.sum(y[idx_trva, i_class]) / np.sum(y[:, i_class])\n",
    "                if te_percent < 0.5 * test_ratio or \\\n",
    "                                trva_percent < 0.5 + 0.5 * test_ratio:\n",
    "                    success_flag = False\n",
    "                    break\n",
    "            if not success_flag:\n",
    "                break\n",
    "        if not success_flag:\n",
    "            continue\n",
    "        cnt2 = 0\n",
    "        while cnt2 < 1000:\n",
    "            cnt2 += 1\n",
    "            success_flag = True\n",
    "            ss2 = StratifiedShuffleSplit(y[idx_trva, i_class_least], n_iter=1,\n",
    "                                         test_size=test_ratio * n_samples / len(idx_trva))\n",
    "            for idx_tr_ss2, idx_va_ss2 in ss2:  # length is only 1 !\n",
    "                idx_tr = idx_trva[idx_tr_ss2]\n",
    "                idx_va = idx_trva[idx_va_ss2]\n",
    "                for i_class in range(n_classes):\n",
    "                    tr_percent = 1.0 * np.sum(y[idx_tr, i_class]) / np.sum(y[:, i_class])\n",
    "                    va_percent = 1.0 * np.sum(y[idx_va, i_class]) / np.sum(y[:, i_class])\n",
    "                    if va_percent < 0.5 * test_ratio or \\\n",
    "                                    tr_percent < 0.5:\n",
    "                        success_flag = False\n",
    "                        break\n",
    "                if not success_flag:\n",
    "                    break\n",
    "            if not success_flag:\n",
    "                continue\n",
    "        if not success_flag:\n",
    "            continue\n",
    "        idx_list[i_trial] = [idx_tr, idx_va, idx_te]\n",
    "        i_trial += 1\n",
    "    return idx_list\n",
    "\n",
    "\n",
    "def make_splits(y, nfold):\n",
    "    if len(y.shape) > 1 and y.shape[1] > 1:\n",
    "        return try_making_splits(y, nfold)\n",
    "    assert nfold > 2\n",
    "    skf = StratifiedKFold(np.array(y).flatten(), nfold, shuffle=True, random_state=0)\n",
    "    idx_trva_list = []\n",
    "    idx_te_list = []\n",
    "    for idx_tr, idx_te in skf:\n",
    "        idx_trva_list.append(idx_tr)\n",
    "        idx_te_list.append(idx_te)\n",
    "\n",
    "    idx_list = np.empty([nfold, 3], dtype=object)\n",
    "    for i in range(nfold):\n",
    "        idx_list[i][0] = np.setdiff1d(idx_trva_list[i], idx_te_list[(i + 1) % nfold], True)\n",
    "        idx_list[i][1] = idx_te_list[(i + 1) % nfold]\n",
    "        idx_list[i][2] = idx_te_list[i]\n",
    "    return idx_list\n",
    "\n",
    "# def get_icd9_subcat_label(icd9_str):\n",
    "#     ss = icd9_str.split('.')[0]\n",
    "#     idx_lb = max(np.where(ss >= subcat_lbs)[0])\n",
    "#     idx_ub = min(np.where(ss[:4] <= subcat_ubs)[0])\n",
    "#     if idx_lb != idx_ub:\n",
    "#         print(idx_lb, idx_ub, icd9_str, ss)\n",
    "#     #assert idx_lb == idx_ub\n",
    "#     return idx_lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters\n",
    "\n",
    "- HRS: Set length of timeseries, unit is hour.\n",
    "- working_path: path where DB_merged_Xhrs.npy, ICD9-Xhrs.npy, AGE_LOS_MORTALITY_Xhrs.npy, ADM_FEATURES_Xhrs.npy, ADM_LABELS_Xhrs.npy are located.\n",
    "- LAB_EVENTS_IDX: indices of features from chartevents and labevents. For these features, we use forward and backward imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Main ####\n",
    "# DATA_NAME = 'mimic319k48h'\n",
    "# Settings for task, model, path, etc\n",
    "# working_path = r'../..'\n",
    "HRS = 24\n",
    "\n",
    "working_path = '../../Data/admdata_17f/%dhrs/' % HRS\n",
    "# raw_data_path = os.path.join(working_path, 'data', DATA_NAME, 'raw')\n",
    "# processed_data_path = os.path.join(working_path, 'data', DATA_NAME)\n",
    "raw_data_path = working_path\n",
    "processed_data_path = os.path.join(working_path, 'series')\n",
    "if not os.path.exists(processed_data_path):\n",
    "    os.makedirs(processed_data_path)\n",
    "\n",
    "LAB_EVENTS_IDX = np.array([0,1,2,3,4,5,7,8,9,10,11,12]) # labevents and chartevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data file\n",
      "load icd9 label file\n",
      "load mor label file\n",
      "load admission features\n",
      "load mortality labels\n",
      "# of samples: 35637\n",
      "[]\n",
      "# of samples > 24 hours: 35637\n",
      "......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done!\n"
     ]
    }
   ],
   "source": [
    "print('load data file')\n",
    "data_all = np.empty([0], dtype=object)\n",
    "for datanpz_file_name in ['DB_merged_%dhrs.npy' % HRS]:\n",
    "    datanpz_file_pathname = os.path.join(raw_data_path,\n",
    "                                         datanpz_file_name)\n",
    "    data_all = np.concatenate((data_all, np.load(datanpz_file_pathname)))\n",
    "\n",
    "print('load icd9 label file')\n",
    "label_icd9_all = np.empty([0], dtype=object)\n",
    "for label_icd9_npz_file_name in ['ICD9-%dhrs.npy' % HRS]:\n",
    "    label_icd9_npz_file_pathname = os.path.join(raw_data_path, \n",
    "                                                label_icd9_npz_file_name)\n",
    "    label_icd9_all = np.concatenate((label_icd9_all, \n",
    "                                    np.load(label_icd9_npz_file_pathname)))\n",
    "\n",
    "# print('load icd9 subcat list file')\n",
    "# subcat_lbs = []\n",
    "# subcat_ubs = []\n",
    "# with open(os.path.join(raw_data_path, 'ICD9_subcat.csv'), 'r') as f:\n",
    "#     for line in f.readlines():\n",
    "#         subcat_id, subcat_lb, subcat_ub = line.split(',')\n",
    "#         subcat_lbs.append(subcat_lb)\n",
    "#         subcat_ubs.append(subcat_ub)\n",
    "#     subcat_lbs = np.array(subcat_lbs)\n",
    "#     subcat_ubs = np.array(subcat_ubs)\n",
    "\n",
    "print('load mor label file')\n",
    "label_mor_all = None\n",
    "for label_mor_npz_file_name in ['AGE_LOS_MORTALITY_%dhrs.npy' % HRS]:\n",
    "    label_mor_npz_file_pathname = os.path.join(raw_data_path,\n",
    "                                               label_mor_npz_file_name)\n",
    "    if label_mor_all is None:\n",
    "        label_mor_all = np.load(label_mor_npz_file_pathname)\n",
    "    else:\n",
    "        label_mor_all = np.concatenate((label_mor_all, \n",
    "                                        np.load(label_mor_npz_file_pathname)))\n",
    "        \n",
    "print('load admission features')\n",
    "adm_features_all = np.load(os.path.join(raw_data_path, 'ADM_FEATURES_%dhrs.npy' % HRS))\n",
    "\n",
    "print('load mortality labels')\n",
    "adm_labels_all = np.load(os.path.join(raw_data_path, 'ADM_LABELS_%dhrs.npy' % HRS))\n",
    "\n",
    "N_all = len(data_all)\n",
    "print('# of samples:', N_all)\n",
    "# get per-frame samples;\n",
    "# imputed-normed-ep (imputation here):    \n",
    "#               ep_tdata_raw, ep_tdata: N * [ti * D]\n",
    "#               ep_tdata_mean, ep_tdata_std: D\n",
    "# normed-ep:    X_t, X_t_mask, deltaT_t: N * [ti * D]\n",
    "#               T_t: N * [ti]\n",
    "X_raw_p48 = np.array([np.array(xx, dtype=float)[:,:-2] for xx in data_all])\n",
    "tsraw_p48 = np.array([np.array(xx, dtype=float)[:,-2] for xx in data_all])\n",
    "del data_all\n",
    "\n",
    "idx_x = np.where([(tt[-1] - tt[0]) > 1.0*60*60*HRS for tt in tsraw_p48])[0]\n",
    "idx_x2 = np.where([(tt[-1] - tt[0]) <= 1.0*60*60*HRS for tt in tsraw_p48])[0]\n",
    "print(idx_x2)\n",
    "N = len(idx_x)\n",
    "print('# of samples > %s hours:' % (HRS), N)\n",
    "assert N_all == N\n",
    "X_raw = X_raw_p48[idx_x]\n",
    "tsraw = tsraw_p48[idx_x]\n",
    "label_icd9_all = label_icd9_all[idx_x]\n",
    "label_mor_all = label_mor_all[idx_x]\n",
    "adm_features_all = adm_features_all[idx_x]\n",
    "adm_labels_all = adm_labels_all[idx_x]\n",
    "\n",
    "for i_n in range(N):\n",
    "    #print i_n\n",
    "    if i_n % 20 == 0:\n",
    "        print('.', end='')\n",
    "        sys.stdout.flush()\n",
    "    for i_t in range(len(X_raw[i_n])):\n",
    "        for i_d in range(len(X_raw[i_n][i_t])):\n",
    "            if X_raw[i_n][i_t][i_d] is None:\n",
    "                X_raw[i_n][i_t][i_d] = np.nan\n",
    "X_raw_all = np.concatenate(X_raw)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ array([ -12335.,   -4535.,    4165.,    4345.,    4405.,    7225.,\n",
      "          7285.,    7345.,    7945.,   10945.,   11545.,   15145.,\n",
      "         18745.,   22345.,   24205.,   24385.,   25945.,   27505.,\n",
      "         29545.,   33145.,   36745.,   40345.,   41365.,   43945.,\n",
      "         44005.,   44665.,   47545.,   51145.,   54745.,   55285.,\n",
      "         56905.,   58345.,   58405.,   61345.,   61945.,   65545.,\n",
      "         67345.,   69145.,   72745.,   74785.,   76345.,   78745.,\n",
      "         79945.,   83545.,   84205.,   87145.,   87265.,   90745.,\n",
      "         91465.,   91645.,   94345.,   97225.,   97945.,  101545.,\n",
      "        105145.,  107185.,  108745.,  112345.,  114985.,  115945.,\n",
      "        116305.,  119545.,  122425.,  123145.,  126745.,  127645.,\n",
      "        128485.,  130345.,  133945.,  134905.,  137545.,  140905.,\n",
      "        141145.,  144745.,  145765.,  146965.,  148345.,  151165.,\n",
      "        151945.,  155545.,  159145.,  159505.,  159805.,  162745.,\n",
      "        164125.,  166345.,  167305.,  167545.,  169945.,  171265.,\n",
      "        173545.,  173785.,  177145.,  180745.,  184285.,  184345.,\n",
      "        187945.,  188485.,  191545.,  195145.,  198745.,  202345.,\n",
      "        205945.,  209545.,  212785.,  213145.,  216685.,  216745.,\n",
      "        216805.,  220345.,  221605.,  223945.,  227545.,  229345.,\n",
      "        231145.,  231625.,  231745.,  234745.,  238345.,  245545.,\n",
      "        247885.,  252745.,  253585.,  263545.,  264505.,  268645.,\n",
      "        285145.,  287845.,  289405.,  291745.,  292345.,  295945.,\n",
      "        299545.,  300805.,  303145.,  303205.,  303565.,  303625.,\n",
      "        306745.,  310345.,  313945.,  317545.,  321145.,  331945.,\n",
      "        332545.,  340345.,  341185.,  346345.,  347425.,  360745.,\n",
      "        411745.,  496645.])\n",
      " array([ -1.56150000e+04,  -8.59500000e+03,   5.85000000e+02,\n",
      "         2.38500000e+03,   4.18500000e+03,   7.78500000e+03,\n",
      "         1.13850000e+04,   1.45050000e+04,   1.49850000e+04,\n",
      "         1.85850000e+04,   2.21850000e+04,   2.38650000e+04,\n",
      "         2.57850000e+04,   2.93850000e+04,   3.29850000e+04,\n",
      "         3.65850000e+04,   4.01850000e+04,   4.37850000e+04,\n",
      "         4.73850000e+04,   5.09850000e+04,   5.45850000e+04,\n",
      "         5.81850000e+04,   6.17850000e+04,   6.53850000e+04,\n",
      "         6.89850000e+04,   7.25850000e+04,   7.61850000e+04,\n",
      "         7.97850000e+04,   8.33850000e+04,   8.69850000e+04,\n",
      "         9.05850000e+04,   9.41850000e+04,   9.77850000e+04,\n",
      "         1.01385000e+05,   1.04985000e+05,   1.08585000e+05,\n",
      "         1.12185000e+05,   1.15785000e+05,   1.19385000e+05,\n",
      "         1.22985000e+05,   1.26585000e+05,   1.30185000e+05,\n",
      "         1.31985000e+05,   1.32285000e+05,   1.33785000e+05,\n",
      "         1.37385000e+05,   1.40085000e+05,   1.40985000e+05,\n",
      "         1.44585000e+05,   1.48185000e+05,   1.51785000e+05,\n",
      "         1.55265000e+05,   1.55385000e+05,   1.58985000e+05,\n",
      "         1.62585000e+05,   1.66185000e+05,   1.69785000e+05,\n",
      "         1.73385000e+05,   1.76985000e+05,   1.80585000e+05,\n",
      "         1.84185000e+05,   1.87785000e+05,   1.91385000e+05,\n",
      "         1.94985000e+05,   1.98585000e+05,   2.02185000e+05,\n",
      "         2.05785000e+05,   2.09385000e+05,   2.12985000e+05,\n",
      "         2.16585000e+05,   2.20185000e+05,   2.23785000e+05,\n",
      "         2.27385000e+05,   2.30985000e+05,   2.31825000e+05,\n",
      "         2.34585000e+05,   2.38185000e+05,   2.41785000e+05,\n",
      "         2.45385000e+05,   2.48985000e+05,   2.52585000e+05,\n",
      "         2.56185000e+05,   2.59785000e+05,   2.70585000e+05,\n",
      "         2.74185000e+05,   2.77785000e+05,   2.81385000e+05,\n",
      "         2.84985000e+05,   2.88585000e+05,   2.92185000e+05,\n",
      "         2.95785000e+05,   2.99385000e+05,   3.02985000e+05,\n",
      "         3.06585000e+05,   3.10185000e+05,   3.13785000e+05,\n",
      "         3.17385000e+05,   3.19785000e+05,   3.20985000e+05,\n",
      "         3.24585000e+05,   3.28185000e+05,   3.31785000e+05,\n",
      "         3.35385000e+05,   3.38985000e+05,   3.42585000e+05,\n",
      "         3.46185000e+05,   3.49785000e+05,   3.53385000e+05,\n",
      "         3.56985000e+05,   3.60585000e+05,   3.64185000e+05,\n",
      "         3.67785000e+05,   3.71385000e+05,   3.74985000e+05,\n",
      "         3.78585000e+05,   3.82185000e+05,   3.85785000e+05,\n",
      "         3.89385000e+05,   3.92985000e+05,   3.94185000e+05,\n",
      "         3.96585000e+05,   4.00185000e+05,   4.03785000e+05,\n",
      "         4.07385000e+05,   4.10985000e+05,   4.14585000e+05,\n",
      "         4.18185000e+05,   4.21785000e+05,   4.25385000e+05,\n",
      "         4.86585000e+05,   5.73885000e+05,   6.59385000e+05,\n",
      "         7.45785000e+05,   8.28585000e+05,   9.09585000e+05,\n",
      "         9.86865000e+05])\n",
      " array([    517.,     757.,    1057.,    1357.,    1657.,    1957.,\n",
      "          2257.,    2557.,    3457.,    6157.,    9757.,   10657.,\n",
      "         13357.,   16957.,   20557.,   24157.,   27757.,   31357.,\n",
      "         34957.,   38557.,   42157.,   45757.,   49357.,   52957.,\n",
      "         56557.,   59257.,   60157.,   63757.,   67357.,   70957.,\n",
      "         74557.,   78157.,   79057.,   81757.,   83557.,   85357.,\n",
      "         87157.,   88957.,   92557.,   96157.,   99757.,  100657.,\n",
      "        101557.,  103357.,  106957.,  110557.,  158257.,  184957.,\n",
      "        185557.,  193357.,  194257.,  195157.,  196957.,  198757.,\n",
      "        199357.,  200557.,  205957.,  207757.,  211357.,  214957.,\n",
      "        218557.,  222157.,  225757.,  229357.,  232957.,  235957.,\n",
      "        236557.,  240157.,  243757.,  247357.,  250957.,  252757.,\n",
      "        258157.,  265357.,  270757.,  276157.,  279757.,  285157.,\n",
      "        294157.,  297757.,  301357.,  308557.,  315517.,  315757.,\n",
      "        322957.,  330157.,  337357.,  344557.,  345457.,  349957.,\n",
      "        351757.,  420757.,  505357.])\n",
      " ...,\n",
      " array([   3252.,    9132.,   12552.,   17232.,   21972.,   26232.,\n",
      "         28452.,   29352.,   30252.,   30372.,   31152.,   32052.,\n",
      "         32952.,   34752.,   36432.,   36552.,   40152.,   43752.,\n",
      "         47352.,   50952.,   52932.,   54552.,   58152.,   61752.,\n",
      "         62052.,   65352.,   68172.,   68952.,   72552.,   76152.,\n",
      "         79752.,   83352.,   86952.,   90552.,   93312.,   94152.,\n",
      "         97752.,  101352.,  104952.,  108552.,  112152.,  115752.,\n",
      "        119352.,  122952.,  126552.,  130152.,  133752.,  137352.,\n",
      "        138072.,  140952.,  144552.,  147252.,  151752.,  153552.,\n",
      "        158952.,  166152.,  173172.,  173352.,  180552.,  184152.,\n",
      "        187752.,  189252.,  194952.,  202152.,  205752.,  209352.,\n",
      "        212952.,  216552.,  220812.,  223752.,  227352.,  230952.,\n",
      "        232752.,  232812.,  238152.,  241752.,  321552.,  494352.,\n",
      "        505452.,  578052.])\n",
      " array([   -759.,    5481.,    8901.,   10461.,   11361.,   13821.,\n",
      "         14121.,   14421.,   14781.,   15021.,   15921.,   16821.,\n",
      "         17721.,   18621.,   19521.,   20421.,   21321.,   22221.,\n",
      "         23121.,   23421.,   24021.,   24921.,   25821.,   26721.,\n",
      "         27381.,   27621.,   28521.,   30321.,   32121.,   34701.,\n",
      "         35721.,   39321.,   42921.,   46521.,   47121.,   48321.,\n",
      "         50121.,   52641.,   53721.,   55521.,   57321.,   60921.,\n",
      "         64521.,   66321.,   68121.,   69921.,   71721.,   75321.,\n",
      "         78921.,   82521.,   86121.,   89721.,  152421.,  252621.,\n",
      "        323721.,  339021.])\n",
      " array([ -5.53000000e+03,   2.30000000e+02,   3.50000000e+02,\n",
      "         4.70000000e+02,   3.53000000e+03,   7.13000000e+03,\n",
      "         1.07300000e+04,   1.43300000e+04,   1.79300000e+04,\n",
      "         2.15300000e+04,   2.51300000e+04,   2.87300000e+04,\n",
      "         2.87900000e+04,   3.10100000e+04,   3.23300000e+04,\n",
      "         3.59300000e+04,   3.89900000e+04,   3.95300000e+04,\n",
      "         4.31300000e+04,   4.67300000e+04,   4.93100000e+04,\n",
      "         5.03300000e+04,   5.39300000e+04,   5.75300000e+04,\n",
      "         5.93300000e+04,   6.03500000e+04,   6.11300000e+04,\n",
      "         6.29300000e+04,   6.38300000e+04,   6.47300000e+04,\n",
      "         6.56300000e+04,   6.57500000e+04,   6.83300000e+04,\n",
      "         7.19300000e+04,   7.21100000e+04,   7.55300000e+04,\n",
      "         7.91300000e+04,   8.27300000e+04,   8.33300000e+04,\n",
      "         8.63300000e+04,   8.99300000e+04,   9.09500000e+04,\n",
      "         9.35300000e+04,   9.46700000e+04,   9.71300000e+04,\n",
      "         1.00730000e+05,   1.04330000e+05,   1.04390000e+05,\n",
      "         1.07930000e+05,   1.11530000e+05,   1.15130000e+05,\n",
      "         1.15190000e+05,   1.18730000e+05,   1.18970000e+05,\n",
      "         1.22330000e+05,   1.25930000e+05,   1.29530000e+05,\n",
      "         1.33130000e+05,   1.36730000e+05,   1.40330000e+05,\n",
      "         1.43930000e+05,   1.47530000e+05,   1.51130000e+05,\n",
      "         1.54730000e+05,   1.58330000e+05,   1.61930000e+05,\n",
      "         1.65530000e+05,   1.69130000e+05,   1.72730000e+05,\n",
      "         1.76330000e+05,   1.79930000e+05,   1.83530000e+05,\n",
      "         1.87130000e+05,   1.90730000e+05,   1.94330000e+05,\n",
      "         1.97930000e+05,   2.01530000e+05,   2.01590000e+05,\n",
      "         2.05130000e+05,   2.05610000e+05,   2.08730000e+05,\n",
      "         2.09330000e+05,   2.09630000e+05,   2.12330000e+05,\n",
      "         2.15930000e+05,   2.19530000e+05,   2.23130000e+05,\n",
      "         2.26730000e+05,   2.30330000e+05,   2.30510000e+05,\n",
      "         2.33930000e+05,   2.37530000e+05,   2.41130000e+05,\n",
      "         2.44730000e+05,   2.48330000e+05,   2.51930000e+05,\n",
      "         2.55530000e+05,   2.59130000e+05,   2.62730000e+05,\n",
      "         2.66330000e+05,   2.69930000e+05,   2.73530000e+05,\n",
      "         2.77130000e+05,   2.80730000e+05,   2.84330000e+05,\n",
      "         2.87930000e+05,   2.87990000e+05,   2.91530000e+05,\n",
      "         2.93210000e+05,   2.95130000e+05,   2.98730000e+05,\n",
      "         3.02330000e+05,   3.05930000e+05,   3.09530000e+05,\n",
      "         3.13130000e+05,   3.16730000e+05,   3.20330000e+05,\n",
      "         3.20930000e+05,   3.23930000e+05,   3.27530000e+05])]\n"
     ]
    }
   ],
   "source": [
    "print(tsraw_p48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get mr and kept idx\n"
     ]
    }
   ],
   "source": [
    "# remove the columns with less observations\n",
    "print('get mr and kept idx')\n",
    "val_mr = np.sum(np.isnan(X_raw_all), axis=0) * 1.0 / X_raw_all.shape[0]\n",
    "keep_val_idx = val_mr < 1-5e-4\n",
    "keep_val_idx_list = np.where(keep_val_idx)\n",
    "X_raw_all_kept = X_raw_all[:,keep_val_idx]\n",
    "X_raw_kept = np.array([xx[:, keep_val_idx] for xx in X_raw])\n",
    "lab_events_idx = LAB_EVENTS_IDX\n",
    "\n",
    "del X_raw_all\n",
    "del X_raw\n",
    "\n",
    "# X_raw_all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the mean value in the first HRS hours, used for SuperLearner\n",
    "# First get the mean of pao2 and fio2, then calc the ratio!!!\n",
    "PAO2_VAR = 4\n",
    "FIO2_VAR = 5\n",
    "RATIO_VAR = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge time series every 5 minutes\n",
    "\n",
    "We merge the data in time series every 5 minutes by using the average value of all values in the 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get mean and std for tdata\n",
      "get X_new and t_new\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/[HOMEDIR]/.pyenv/versions/anaconda3-4.4.0/lib/python3.6/site-packages/ipykernel_launcher.py:32: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "print('get mean and std for tdata')\n",
    "n_temporal_var = X_raw_all_kept.shape[1]    # last frame is time t in seconds\n",
    "ep_tdata_mean = np.nanmean(X_raw_all_kept, axis=0)\n",
    "ep_tdata_std = np.nanstd(X_raw_all_kept, axis=0)\n",
    "del X_raw_all_kept\n",
    "\n",
    "# get ep data with mask and deltaT\n",
    "# 0-mean, 1-std, merge observations within 5 mins\n",
    "merging_mins = 5\n",
    "print('get X_new and t_new')\n",
    "X_new = np.empty([N], dtype=object)\n",
    "t_new = np.empty([N], dtype=object)\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.',end='')\n",
    "        sys.stdout.flush()\n",
    "    tsraw[i] = tsraw[i].flatten()\n",
    "    t = 0\n",
    "    X_new[i] = []\n",
    "    t_new[i] = []\n",
    "    while t < len(tsraw[i]):\n",
    "        t1 = t+1\n",
    "        while t1 < len(tsraw[i]) and tsraw[i][t1] - tsraw[i][t] <= merging_mins*60:\n",
    "            t1 += 1\n",
    "        # merge [t:t1]\n",
    "#         X_new[i].append(\n",
    "#             (np.nanmean(X_raw_kept[i][t:t1,:], axis=0) - ep_tdata_mean) \\\n",
    "#                 /ep_tdata_std\n",
    "#             )\n",
    "        # Here we do not normalize the data!!!\n",
    "        X_new[i].append(\n",
    "            np.nanmean(X_raw_kept[i][t:t1,:], axis=0)\n",
    "            )\n",
    "        # X_new[i].append(np.nanmean(X_raw_kept[i][t:t1,:], axis=0))\n",
    "        t_new[i].append(int((tsraw[i][t1-1]+tsraw[i][t])/2))\n",
    "        t = t1\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('get X_t, mask, etc')\n",
    "X_t = np.empty([N], dtype=object)        # N * [t*d]\n",
    "X_t_mask = np.empty([N], dtype=object)   # N * [t*d]\n",
    "T_t = t_new                                 # N * [t]\n",
    "deltaT_t = np.empty([N], dtype=object)   # N * [t*d]\n",
    "for i in range(N):\n",
    "    if i % 20 == 0:\n",
    "        print('.',end='')\n",
    "        sys.stdout.flush()\n",
    "    X_t[i] = np.vstack(X_new[i])\n",
    "    X_t_mask[i] = 1-np.isnan(X_t[i]).astype('int8')\n",
    "    X_t[i][np.isnan(X_t[i])] = 0\n",
    "    deltaT_t[i] = np.zeros_like(X_t[i], dtype=int)\n",
    "    deltaT_t[i][0,:] = 0\n",
    "    for i_t in range(1, len(T_t[i])):\n",
    "        deltaT_t[i][i_t,:] = T_t[i][i_t] - T_t[i][i_t-1] + \\\n",
    "            (1-X_t_mask[i][i_t-1,:]) * deltaT_t[i][i_t-1,:]\n",
    "print('done!')\n",
    "del X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract subcat labels\n",
    "# for i_n, label_i in enumerate(label_icd9_all):\n",
    "#     for i_li, label_vec in enumerate(label_i):\n",
    "#         subcat = get_icd9_subcat_label(label_vct[2])\n",
    "#         label_i[i_li].append(subcat)\n",
    "#     label_icd9_all[i_n] = label_i\n",
    "        \n",
    "# get labels\n",
    "print('get labels')\n",
    "class_icd9_counts = np.bincount(\n",
    "    np.concatenate(label_icd9_all)[:,3].astype(int))\n",
    "class_icd9_list = np.where(class_icd9_counts > 10)[0]\n",
    "class_icd9_list.sort()\n",
    "\n",
    "# class_icd9_subcat_counts = np.bincount(\n",
    "#     np.concatenate(label_icd9_all)[:,4].astype(int))\n",
    "# class_icd9_subcat_list = np.where(class_icd9_subcat_counts >= 200)[0]\n",
    "# class_icd9_subcat_list.sort()\n",
    "\n",
    "n_class_icd9 = class_icd9_list.shape[0]\n",
    "# n_class_icd9_subcat = class_icd9_subcat_list.shape[0]\n",
    "y_icd9 = np.zeros([N, n_class_icd9], dtype=int)\n",
    "# y_icd9_subcat = np.zeros([N, n_class_icd9_subcat], dtype=int)\n",
    "for i_n, label_i in enumerate(label_icd9_all):\n",
    "        for label_vec in label_i:\n",
    "            class_idx = np.array(\n",
    "                [cl == label_vec[3] for cl in class_icd9_list],\n",
    "                dtype=bool)\n",
    "            y_icd9[i_n][class_idx] = 1\n",
    "#             subcat_idx = np.array(\n",
    "#                 [cl == label_vec[4] for cl in class_icd9_subcat_list],\n",
    "#                 dtype=bool)\n",
    "#             y_icd9_subcat[i_n][subcat_idx] = 1\n",
    "\n",
    "y_mor = np.expand_dims(np.array(label_mor_all[:,4], dtype=int), axis=1)\n",
    "age_days = label_mor_all[:, 2]\n",
    "y_los = label_mor_all[:, 3]\n",
    "            \n",
    "# print('# of class, subcat:', n_class_icd9, n_class_icd9_subcat)\n",
    "print('# of class, subcat:')\n",
    "\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep-stats.npz'), \n",
    "         class_icd9_list=class_icd9_list, \n",
    "         class_icd9_counts=class_icd9_counts,\n",
    "#          class_icd9_subcat_list=class_icd9_subcat_list,\n",
    "#          class_icd9_subcat_counts=class_icd9_subcat_counts,\n",
    "         keep_val_idx_list=keep_val_idx_list, \n",
    "         ep_tdata_mean=ep_tdata_mean, ep_tdata_std=ep_tdata_std,\n",
    "         n_class_icd9=n_class_icd9, \n",
    "#          n_class_icd9_subcat=n_class_icd9_subcat,\n",
    "         N=N, val_mr=val_mr, idx_x=idx_x, age_days=age_days)\n",
    "\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep.npz'), \n",
    "         X_t=X_t,X_t_mask=X_t_mask,T_t=T_t,deltaT_t=deltaT_t,\n",
    "         y_icd9=y_icd9, y_mor=y_mor, adm_features_all=adm_features_all, adm_labels_all=adm_labels_all,y_los=y_los)\n",
    "# , y_icd9_subcat=y_icd9_subcat)\n",
    "\n",
    "del X_t, X_t_mask, deltaT_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate time series without sampling and imputation\n",
    "\n",
    "After this step, we get:\n",
    "- normed-ep-ratio.npz: data after averaging and before sampling. **For 17 processed features, we should use norm-ep-ratio.npz since it includes PaO2/FiO2 ratio**.\n",
    "    - ‘X_t’: temporal data. Shape: [number of admissions][number of timestamps, number of temporal features].\n",
    "    - ‘X_t_mask’: masks of temporal data. Shape: [number of admissions][number of timestamps, number of temporal features].\n",
    "    - ‘T_t’: timestamps of temporal data: num of seconds from current record to the icu admission time. Shape: [number of admissions][number of timestamps].\n",
    "    - ‘deltaT_t’: number of seconds from current record to the latest valid (not none) record before it. Shape: [number of admissions][number of timestamps].\n",
    "    - ‘y_icd9’: icd9 labels. Shape: [number of admissions, number of icd9 categories].\n",
    "    - ‘y_mor’: in-hospital mortality labels. Shape: [number of admissions].\n",
    "    - ‘adm_features_all’: non-temporal features of admissions, containing: age(days)/acquired immunodeficiency syndrome/hematologic malignancy/metastatic cancer/admission type. Shape: [number of admissions, number of non-temporal features=5].\n",
    "    - ‘adm_labels_all’: mortality labels of admissions, containing: in-hospital/1-day/2-day/3-day/30-day/1-year mortality. Shape: [number of admissions, number of mortality labels=6].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell calculates the PaO2/FiO2 ratio based on normed-ep.npz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ep_origin = np.load(os.path.join(processed_data_path, 'normed-ep.npz'))\n",
    "# Here we merge pao2 and fio2 and get pf ratio\n",
    "X_t_ratio = []\n",
    "X_t_ratio_mask = []\n",
    "T_t_ratio = []\n",
    "deltaT_t_ratio = []\n",
    "X_t_origin, X_t_origin_mask, T_t_origin, deltaT_t_origin = ep_origin['X_t'], ep_origin['X_t_mask'], ep_origin['T_t'], ep_origin['deltaT_t']\n",
    "for t in range(X_t_origin.shape[0]):\n",
    "    if t % 20 == 0:\n",
    "        print('.', end='')\n",
    "    xto = X_t_origin[t]\n",
    "    xtom = X_t_origin_mask[t]\n",
    "    tto = T_t_origin[t]\n",
    "    dto = deltaT_t_origin[t]\n",
    "    ratio_shape = (xto.shape[0], xto.shape[1] - 1)\n",
    "    xto_ratio = np.full(ratio_shape, np.nan)\n",
    "    xtom_ratio = np.full(ratio_shape, np.nan)\n",
    "    tto_ratio = tto\n",
    "    dto_ratio = np.full(ratio_shape, np.nan)\n",
    "    # keep others\n",
    "    for itratio, it in zip([xto_ratio, xtom_ratio, dto_ratio],[xto, xtom, dto]):\n",
    "        itratio[:, :PAO2_VAR] = it[:, :PAO2_VAR]\n",
    "        itratio[:, FIO2_VAR:] = it[:, FIO2_VAR + 1:]\n",
    "    # fix the ratio part\n",
    "    xto_ratio[:, PAO2_VAR] = xto[:, PAO2_VAR] / xto[:, FIO2_VAR]\n",
    "    xto_ratio[np.isinf(xto_ratio)] = np.nan\n",
    "    xtom_ratio[:, PAO2_VAR] = np.logical_and(xtom[:, PAO2_VAR], xtom[:, FIO2_VAR])\n",
    "    dto_ratio[:, PAO2_VAR] = np.zeros_like(dto[:, PAO2_VAR])\n",
    "    for i_t in range(1, len(tto_ratio)):\n",
    "        dto_ratio[i_t,PAO2_VAR] = tto_ratio[i_t] - tto_ratio[i_t-1] + \\\n",
    "            (1-xtom_ratio[i_t-1,PAO2_VAR]) * dto_ratio[i_t-1,PAO2_VAR]\n",
    "    X_t_ratio.append(xto_ratio)\n",
    "    X_t_ratio_mask.append(xtom_ratio)\n",
    "    T_t_ratio.append(tto_ratio)\n",
    "    deltaT_t_ratio.append(dto_ratio)\n",
    "X_t_ratio = np.array(X_t_ratio, dtype=object)\n",
    "X_t_ratio_mask = np.array(X_t_ratio_mask, dtype=object)\n",
    "T_t_ratio = np.array(T_t_ratio, dtype=object)\n",
    "deltaT_t_ratio = np.array(deltaT_t_ratio, dtype=object)\n",
    "np.savez(os.path.join(processed_data_path, 'normed-ep-ratio.npz'), \n",
    "         X_t=X_t_ratio,X_t_mask=X_t_ratio_mask,T_t=T_t_ratio,deltaT_t=deltaT_t_ratio,\n",
    "         y_icd9=ep_origin['y_icd9'], y_mor=ep_origin['y_mor'], adm_features_all=ep_origin['adm_features_all'], adm_labels_all=ep_origin['adm_labels_all'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling and imputation\n",
    "\n",
    "After this step, we get the following files:\n",
    "- imputed-normed-ep_X_Y.npz: data after sampling and imputation. X (hours) is the length of interval of sampling and Y (hours) is the length of time series.\n",
    "    - ‘ep_data’: concatenated temporal data. Shape: [number of admissions, Y/X * number of temporal features].\n",
    "    - ‘ep_tdata’: temporal data. Shape: [number of admissions, Y/X, number of temporal features].\n",
    "    - ‘ep_data_masking’: concatenated masking of temporal data. Shape: [number of admissions, Y/X * number of temporal features].\n",
    "    - ‘ep_tdata_masking’: masking of temporal data. Shape: [number of admissions, Y/X, number of temporal features].\n",
    "    - ‘y_icd9’: icd9 labels. Shape: [number of admissions, number of icd9 categories].\n",
    "    - ‘y_mor’: in-hospital mortality labels. Shape: [number of admissions].\n",
    "    - ‘adm_features_all’: non-temporal features of admissions, containing: age(days)/acquired immunodeficiency syndrome/hematologic malignancy/metastatic cancer/admission type. Shape: [number of admissions, number of non-temporal features=5].\n",
    "    - ‘adm_labels_all’: mortality labels of admissions, containing: in-hospital/1-day/2-day/3-day/30-day/1-year mortality. Shape: [number of admissions, number of mortality labels=6].\n",
    "    - ‘y_los’: length of stay of admissions, unit is minute. Shape: [number of admissions].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get first N hours data\n",
    "# one data sample for one patient\n",
    "# hours_list = [(2, 24), (1, 24), (1, 48), (2, 48)]\n",
    "hours_list = [(2, HRS), (1, HRS)]\n",
    "for n_sample_hour, n_full_hour in hours_list:\n",
    "    print('get X_miss', n_sample_hour, n_full_hour)\n",
    "    #n_sample_hour = 2\n",
    "    #n_full_hour = HRS\n",
    "    n_time_step = int(n_full_hour / n_sample_hour)\n",
    "    # get X_miss first from X_raw_all_kept and tsraw, (sampled)\n",
    "    X_miss = np.empty([N], dtype = object)\n",
    "    T_miss = np.zeros([N], dtype = int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        T_miss[i_n] = math.ceil(\n",
    "            (tsraw[i_n][-1]-tsraw[i_n][0])*1.0/(60*60*n_sample_hour))\n",
    "        X_miss[i_n] = np.zeros([T_miss[i_n], n_temporal_var], dtype=float)\n",
    "        for i_t in range(T_miss[i_n]):\n",
    "            t_idx = np.logical_and(\n",
    "                (tsraw[i_n]-tsraw[i_n][0]) >= i_t*(60*60*n_sample_hour),\n",
    "                (tsraw[i_n]-tsraw[i_n][0]) <= (1+i_t) * (60*60*n_sample_hour))\n",
    "            X_raw_thist = X_raw_kept[i_n][t_idx, :]\n",
    "            # Here we do not normalize the data!!!\n",
    "#             X_miss[i_n][i_t,:] = \\\n",
    "#                 (np.nanmean(X_raw_thist, axis=0) - ep_tdata_mean) / ep_tdata_std\n",
    "            X_miss[i_n][i_t,:] = np.nanmean(X_raw_thist, axis=0)\n",
    "    print('done!')\n",
    "    # X_imputed: do forward/backward imputing from X_miss for lab events\n",
    "    #            do mean imputing for other events\n",
    "    print('get X_imputed')\n",
    "    X_imputed = deepcopy(X_miss)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        i_n_mean = np.nanmean(X_imputed[i_n], axis=0)\n",
    "        for i_t in range(1, T_miss[i_n]):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    if keep_val_idx_list[0][i_d] in lab_events_idx:\n",
    "                        X_imputed[i_n][i_t, i_d] = X_imputed[i_n][i_t-1, i_d]\n",
    "        for i_t in range(T_miss[i_n]-2, -1, -1):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    if keep_val_idx_list[0][i_d] in lab_events_idx:\n",
    "                        X_imputed[i_n][i_t, i_d] = X_imputed[i_n][i_t+1, i_d]\n",
    "        # X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "        # Here we use mean value of each feature in current time series to impute nans\n",
    "        for i_t in range(0, T_miss[i_n]):\n",
    "            for i_d in range(n_temporal_var):\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    X_imputed[i_n][i_t, i_d] = i_n_mean[i_d]\n",
    "        # for values which are still none, just impute with 0\n",
    "#         X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "    print('done!')\n",
    "        \n",
    "    # get first # hours, for both data and masking\n",
    "    print('get ep_tdata')\n",
    "    ep_tdata = np.zeros([N, n_time_step, n_temporal_var], dtype=float)\n",
    "    ep_tdata_masking = np.zeros_like(ep_tdata, dtype=int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        xx_imp = X_imputed[i_n]\n",
    "        xx_mis = X_miss[i_n]\n",
    "        tt_min = min(n_time_step, len(xx_imp))\n",
    "        assert tt_min > 0\n",
    "        ep_tdata[i_n, :tt_min, :] = xx_imp[:tt_min, :]\n",
    "        ep_tdata[i_n, tt_min:, :] = ep_tdata[i_n, tt_min-1, :][None, :]\n",
    "        ep_tdata_masking[i_n, :tt_min, :] = \\\n",
    "            (~np.isnan(xx_mis[:tt_min, :])).astype(int)\n",
    "    print('done!')\n",
    "    \n",
    "    # After imputation, calc the pf ratio!!!\n",
    "    print('calculating pao2/fio2 ratio...')\n",
    "    ep_tdata_withr = np.zeros([N, n_time_step, n_temporal_var - 1], dtype=float)\n",
    "    ep_tdata_masking_withr = np.zeros_like(ep_tdata_withr, dtype=int)\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        pfratio = ep_tdata[i_n, :, PAO2_VAR] / ep_tdata[i_n, :, FIO2_VAR]\n",
    "        pfratio_masking = np.logical_and(ep_tdata_masking[i_n, :, PAO2_VAR] == 1,\n",
    "                                        ep_tdata_masking[i_n, :, FIO2_VAR] == 1).astype(int)\n",
    "        ep_tdata_withr[i_n, :, :PAO2_VAR] = ep_tdata[i_n, :, :PAO2_VAR]\n",
    "        ep_tdata_withr[i_n, :, PAO2_VAR] = pfratio\n",
    "        ep_tdata_withr[i_n, :, FIO2_VAR:] = ep_tdata[i_n, :, FIO2_VAR + 1:]\n",
    "        ep_tdata_masking_withr[i_n, :, :PAO2_VAR] = ep_tdata_masking[i_n, :, :PAO2_VAR]\n",
    "        ep_tdata_masking_withr[i_n, :, PAO2_VAR] = pfratio_masking\n",
    "        ep_tdata_masking_withr[i_n, :, FIO2_VAR:] = ep_tdata_masking[i_n, :, FIO2_VAR + 1:]\n",
    "    ep_tdata_withr[np.isinf(ep_tdata_withr)] = np.nan\n",
    "#     ep_tdata_masking_withr[np.isnan(ep_tdata_withr)] = 0\n",
    "    print('done!')\n",
    "    \n",
    "    # After calc ratio, impute the ratio!!!\n",
    "    print('imputing pao2/fio2 ratio...')\n",
    "    print('get X_withr_imputed')\n",
    "    for i_n in range(N):\n",
    "        if i_n % 20 == 0:\n",
    "            print('.',end='')\n",
    "            sys.stdout.flush()\n",
    "        i_n_mean = np.nanmean(ep_tdata_withr[i_n], axis=0)\n",
    "        tslen = ep_tdata_withr[i_n].shape[0]\n",
    "        for i_t in range(1, tslen):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(ep_tdata_withr[i_n, i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = ep_tdata_withr[i_n, i_t - 1, i_d]\n",
    "        for i_t in range(tslen-2, -1, -1):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(X_imputed[i_n][i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = ep_tdata_withr[i_n, i_t+1, i_d]\n",
    "        # X_imputed[i_n][np.isnan(X_imputed[i_n])] = 0\n",
    "        # Here we use mean value of each feature in current time series to impute nans\n",
    "        for i_t in range(0, tslen):\n",
    "            for i_d in [PAO2_VAR]:\n",
    "                if np.isnan(ep_tdata_withr[i_n, i_t, i_d]):\n",
    "                    ep_tdata_withr[i_n, i_t, i_d] = i_n_mean[i_d]\n",
    "    # for values which are still none, just impute with 0\n",
    "#     ep_tdata_withr[np.isnan(ep_tdata_withr)] = 0\n",
    "    print('done!')\n",
    "    \n",
    "#     assert ep_tdata_withr[np.isnan(ep_tdata_withr)].shape == (0,)\n",
    "    \n",
    "    n_temporal_var_withr = n_temporal_var - 1\n",
    "    ep_data_withr = np.reshape(ep_tdata_withr, [N, n_time_step*n_temporal_var_withr])\n",
    "    ep_data_masking_withr = np.reshape(ep_tdata_masking_withr, [N, n_time_step*n_temporal_var_withr])\n",
    "    \n",
    "    np.savez(os.path.join(processed_data_path, \n",
    "                          'imputed-normed-ep' + '_' + str(n_sample_hour) + \\\n",
    "                          '_' + str(n_full_hour) + '.npz'), \n",
    "             ep_data = ep_data_withr, ep_tdata = ep_tdata_withr,\n",
    "             ep_data_masking = ep_data_masking_withr, \n",
    "             ep_tdata_masking = ep_tdata_masking_withr,\n",
    "             y_icd9 = y_icd9, y_mor = y_mor,adm_features_all=adm_features_all, adm_labels_all=adm_labels_all,y_los=y_los)\n",
    "#     , y_icd9_subcat=y_icd9_subcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_icd9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making stratified folds and normalizing\n",
    "\n",
    "After this step, we get the following files:\n",
    "- 5-folds.npz: folds file containing indices of each fold. Folds are generated with stratified k-fold, which keeps the ratio of positive samples in training/test set. Therefore we generate a set of folds for each label. In each fold, we have 3 lists: indices of training/validation/test set.\n",
    "    - ‘folds_ep_icd9’: Sets of folds for icd9 classification tasks. Shape: [number of icd9 categories, 1(for compatibility), number of folds=5, 3(training/validation/test)].\n",
    "    - ‘folds_ep_icd9_multi’: For multi-classification of icd9, we only generate one set of folds based on the category of icd9 with fewest positive samples. Shape: [1, 1(for compatibility), number of folds=5, 3(training/validation/test)].\n",
    "    - ‘folds_ep_mor’: Sets of folds for mortality classification tasks. Shape: [number of  mortality kinds, 1(for compatibility), number of folds=5, 3(training/validation/test)].\n",
    "    - For length of stay regression task, we use the same folds with those used for in-hospital mortality task.\n",
    "- normed-ep-stdized.npz/normed-ep-ratio-stdized.npz/imputed-normed-ep_X_Y-stdized.npz: mean and standard error of each feature of normed-ep/normed-ep-ratio/imputed-normed-ep_X_Y. For each fold in 5-folds.npz file, we have the mean and standard error for temporal and non-temporal data. These parameters are calculated only with training data in order to prevent information leakage, and will be used for data normalization.\n",
    "    - ‘folds_ep_icd9’: shape: [number of icd9 categories, 1(for compatibility), number of folds=5, 2(temporal/non-temporal), 2(mean/standard error)].\n",
    "    - ‘folds_ep_icd9_multi’: shape: [1, 1(for compatibility), number of folds=5, 2(temporal/non-temporal), 2(mean/standard error)].\n",
    "    - ‘folds_ep_mor’: shape: [number of mortality kinds, 1(for compatibility), number of folds=5, 2(temporal/non-temporal), 2(mean/standard error)].\n",
    "    - For length of stay regression task, we use the same parameters with those used for in-hospital mortality task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# imputed_data = np.load('../../Data/admdata_17f/24hrs_raw/series/imputed-normed-ep_1_24.npz')\n",
    "# y_icd9 = imputed_data['y_icd9']\n",
    "# adm_labels_all = imputed_data['adm_labels_all']\n",
    "\n",
    "print('make splits')\n",
    "# make 5-fold cv splits if file not exists\n",
    "def make_splits_on(y_mor, foldn):\n",
    "    folds_ep_mor = []\n",
    "    for i in range(1):\n",
    "        folds_ep_mor.append(make_splits(y_mor, foldn))\n",
    "    return folds_ep_mor\n",
    "\n",
    "def gen_folds_ids(foldn, fold_file_path, **kwargs):\n",
    "    # generate folds based on label sets\n",
    "    folds = {}\n",
    "    for labelname, (labelarray, is_multi_task) in kwargs.items():\n",
    "        assert len(labelarray.shape) > 1\n",
    "        folds[labelname] = []\n",
    "        if is_multi_task:\n",
    "            for ln in range(labelarray.shape[1]):\n",
    "                tempy = labelarray[:, ln]\n",
    "                try:\n",
    "                    lnfold = make_splits_on(tempy, foldn)\n",
    "                except:\n",
    "                    print('pass {0} {1}'.format(labelname, ln))\n",
    "                    lnfold = None\n",
    "                folds[labelname].append(lnfold)\n",
    "        else:\n",
    "            folds[labelname].append(make_splits_on(labelarray, foldn))\n",
    "    np.savez(fold_file_path, **folds)\n",
    "    return folds\n",
    "\n",
    "def get_standardize_stats_for_training(ep_tdata, ep_tdata_masking, adm_features_all, training_ids):\n",
    "    trainset = ep_tdata[training_ids]\n",
    "    trainset_masking = ep_tdata_masking[training_ids]\n",
    "    train_admfeatures = adm_features_all[training_ids]\n",
    "    id_num = trainset.shape[0]\n",
    "    dim = trainset.shape[2]\n",
    "    stats = np.empty((dim, 2)) * np.nan\n",
    "    for d in range(dim):\n",
    "        dim_values = trainset[:,:,d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        stats[d,:] = np.array([dim_mean, dim_std])\n",
    "    nsdim = adm_features_all.shape[1]\n",
    "    nsstats = np.empty((nsdim, 2)) * np.nan\n",
    "    for d in range(nsdim):\n",
    "        dim_values = train_admfeatures[:, d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        nsstats[d,:] = np.array([dim_mean, dim_std])\n",
    "    return stats, nsstats\n",
    "\n",
    "def get_standardize_stats_for_training_missing(ep_tdata, ep_tdata_masking, adm_features_all, training_ids):\n",
    "    trainset = np.concatenate(ep_tdata[training_ids])\n",
    "    trainset_masking = np.concatenate(ep_tdata_masking[training_ids])\n",
    "    train_admfeatures = adm_features_all[training_ids]\n",
    "    id_num = trainset.shape[0]\n",
    "    dim = trainset.shape[1]\n",
    "    stats = np.empty((dim, 2)) * np.nan\n",
    "    for d in range(dim):\n",
    "        dim_masking = trainset_masking[:,d].flatten()\n",
    "        dim_values = trainset[:,d].flatten()[np.where(dim_masking==1)]\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        stats[d,:] = np.array([dim_mean, dim_std])\n",
    "    nsdim = adm_features_all.shape[1]\n",
    "    nsstats = np.empty((nsdim, 2)) * np.nan\n",
    "    for d in range(nsdim):\n",
    "        dim_values = train_admfeatures[:, d].flatten()\n",
    "        dim_mean = np.nanmean(dim_values)\n",
    "        dim_std = np.nanstd(dim_values)\n",
    "        nsstats[d,:] = np.array([dim_mean, dim_std])\n",
    "    return stats, nsstats\n",
    "\n",
    "def get_standardize_stats_for_folds(folds, stdfunc, ep_tdata, ep_tdata_masking, adm_features_all):\n",
    "    statsdict = {}\n",
    "    for key, value in folds.items():\n",
    "        statsdict[key] = []\n",
    "        for folds_ids in value:\n",
    "            foldsstat = []\n",
    "            for folds_ep_mor in folds_ids:\n",
    "                foldsn = folds_ep_mor.shape[0]\n",
    "                stats = []\n",
    "                ep_tdata_stdized_list = []\n",
    "                for foldn in range(foldsn):\n",
    "                    training_ids = folds_ep_mor[foldn,0]\n",
    "                    stat, nsstat = stdfunc(ep_tdata=ep_tdata, ep_tdata_masking=ep_tdata_masking, adm_features_all=adm_features_all, training_ids=training_ids)\n",
    "                    fstat = [stat[:, 0], stat[:, 1]]\n",
    "                    fnsstat = [nsstat[:, 0], nsstat[:, 1]]\n",
    "                    stats.append([fstat, fnsstat])\n",
    "                foldsstat.append(np.array(stats))\n",
    "            statsdict[key].append(foldsstat)\n",
    "    return statsdict\n",
    "\n",
    "def split_dataset(datasetfilename, ep_tdata_attr, ep_tdata_masking_attr, ep_adm_features_all_attr, aidwhere, statfunc, foldn, fold_filedir, **kwargs):\n",
    "    dataset = np.load(os.path.join(processed_data_path, datasetfilename + '.npz'))\n",
    "    subdataset = {}\n",
    "    for key, value in dataset.items():\n",
    "        subdataset[key] = value[aidwhere]\n",
    "    sub_tdata = subdataset[ep_tdata_attr]\n",
    "    sub_masking = subdataset[ep_tdata_masking_attr]\n",
    "    sub_label_all = subdataset[ep_adm_features_all_attr]\n",
    "    sublabelset = {}\n",
    "    for key, (value, is_multi_task) in kwargs.items():\n",
    "        sublabelset[key] = (value[aidwhere], is_multi_task)\n",
    "    if not os.path.exists(fold_filedir):\n",
    "        os.makedirs(fold_filedir)\n",
    "    fold_file_path = os.path.join(fold_filedir, '%d-folds.npz' % foldn)\n",
    "    folds = gen_folds_ids(foldn=foldn, fold_file_path=fold_file_path, **sublabelset)\n",
    "    statsdict = get_standardize_stats_for_folds(folds, statfunc, ep_tdata=sub_tdata, ep_tdata_masking=sub_masking, adm_features_all=sub_label_all)\n",
    "    np.savez(os.path.join(fold_filedir, datasetfilename+'-stdized.npz'), **statsdict)\n",
    "#     if not os.path.exists(os.path.join(fold_filedir, datasetfilename+'.npz')):\n",
    "    np.savez(os.path.join(fold_filedir, datasetfilename+'.npz'), **subdataset)\n",
    "    print('finish', fold_filedir)\n",
    "\n",
    "from utils import getConnection\n",
    "\n",
    "# select ids in carevue\n",
    "sql = 'select distinct hadm_id from mimiciii.icustays where dbsource = \\'metavision\\' '\n",
    "sql += 'UNION select distinct hadm_id from mimiciii.transfers where dbsource = \\'metavision\\''\n",
    "conn = getConnection()\n",
    "cur = conn.cursor()\n",
    "cur.execute(sql)\n",
    "res = cur.fetchall()\n",
    "mvaids = sorted([r[0] for r in res])\n",
    "mvaidset = set(mvaids)\n",
    "\n",
    "MVDIR = os.path.join(processed_data_path, 'mv')\n",
    "CVDIR = os.path.join(processed_data_path, 'cv')\n",
    "ALLDIR = processed_data_path\n",
    "data_all = np.load(os.path.join(working_path, 'DB_merged_%dhrs.npy' % HRS))\n",
    "allaids = np.array([t[0][-1] for t in data_all])\n",
    "mvwhere = np.array([aid in mvaidset for aid in allaids])\n",
    "cvwhere = ~mvwhere\n",
    "allwhere = np.logical_or(mvwhere, cvwhere)\n",
    "assert np.alltrue(allwhere)\n",
    "\n",
    "file_list = ['imputed-normed-ep_1_%d'%HRS, 'imputed-normed-ep_2_%d'%HRS]\n",
    "for filename in file_list:\n",
    "    for ids, dirname in zip([mvwhere, cvwhere, allwhere], [MVDIR, CVDIR, ALLDIR]):\n",
    "        split_dataset(\n",
    "            datasetfilename=filename,\n",
    "            ep_tdata_attr='ep_tdata',\n",
    "            ep_tdata_masking_attr='ep_tdata_masking',\n",
    "            ep_adm_features_all_attr='adm_features_all',\n",
    "            aidwhere=ids,\n",
    "            statfunc=get_standardize_stats_for_training,\n",
    "            foldn=5,\n",
    "            fold_filedir=dirname,\n",
    "            folds_ep_icd9=(y_icd9, True),\n",
    "            folds_ep_icd9_multi=(y_icd9, False),\n",
    "            folds_ep_mor=(adm_labels_all, True)\n",
    "        )\n",
    "        \n",
    "ep_datafilename = 'normed-ep-ratio'\n",
    "for ids, dirname in zip([mvwhere, cvwhere, allwhere], [MVDIR, CVDIR, ALLDIR]):\n",
    "    split_dataset(\n",
    "        datasetfilename=ep_datafilename,\n",
    "        ep_tdata_attr='X_t',\n",
    "        ep_tdata_masking_attr='X_t_mask',\n",
    "        ep_adm_features_all_attr='adm_features_all',\n",
    "        aidwhere=ids,\n",
    "        statfunc=get_standardize_stats_for_training_missing,\n",
    "        foldn=5,\n",
    "        fold_filedir=dirname,\n",
    "        folds_ep_icd9=(y_icd9, True),\n",
    "        folds_ep_icd9_multi=(y_icd9, False),\n",
    "        folds_ep_mor=(adm_labels_all, True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check some plot\n",
    "k = 4\n",
    "\n",
    "# pao2 / fio2\n",
    "checkx = np.load(os.path.join(processed_data_path, 'imputed-normed-ep_1_%d.npz'%HRS))['ep_tdata']\n",
    "checkidx = np.random.randint(checkx.shape[0])\n",
    "heart_rate = checkx[checkidx, :, k]\n",
    "print(heart_rate)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(heart_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
